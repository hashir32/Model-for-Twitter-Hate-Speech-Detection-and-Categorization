Toxicity Classification for Twitter Hate Speech Detection

This project is an end-to-end machine learning pipeline designed to classify toxicity in Twitter data. It addresses dataset imbalance using undersampling techniques and experiments with multiple modelsâ€”including Naive Bayes (with TF-IDF), RNNs with LSTMs, and BERT. BERT emerged as the optimal model, achieving an accuracy of 83% and an F1-score of 0.76. The project features robust evaluation using precision-recall metrics and confusion matrices, ensuring reliable detection of toxic content in social media posts.
