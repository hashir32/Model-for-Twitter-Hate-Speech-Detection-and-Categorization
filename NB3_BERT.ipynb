{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv6AAmuVK3s9",
        "outputId": "25e72061-0891-4680-812a-4b3b451570be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "368JwJtNK3tE"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from scipy import sparse\n",
        "%matplotlib inline\n",
        "seed = 42\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '4'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg7OicbsK3tF",
        "outputId": "7d65f803-2f4a-4968-ca57-8c0c4bb2d5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries and mounting Google Drive for data access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Reading the training and testing data along with labels\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/ML_PROJECT/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/ML_PROJECT/test.csv')\n",
        "test_labels = pd.read_csv('/content/drive/MyDrive/ML_PROJECT/test_labels.csv')\n",
        "\n",
        "# Merging test data with labels and filtering rows with label '-1'\n",
        "test_merged = pd.merge(test_data, test_labels, on='id')\n",
        "test_filtered = test_merged[(test_merged.iloc[:, 2:] != -1).all(axis=1)]\n",
        "\n",
        "# Separating toxic and non-toxic comments in the training data\n",
        "toxic_comments = train_data[train_data.iloc[:, 2:].sum(axis=1) > 0]\n",
        "non_toxic_comments = train_data[train_data.iloc[:, 2:].sum(axis=1) == 0]\n",
        "\n",
        "# Balancing the dataset to address class imbalance\n",
        "if len(non_toxic_comments) > len(toxic_comments):\n",
        "    non_toxic_sample = non_toxic_comments.sample(n=len(toxic_comments), random_state=42)\n",
        "    balanced_data = pd.concat([toxic_comments, non_toxic_sample])\n",
        "else:\n",
        "    toxic_sample = toxic_comments.sample(n=len(non_toxic_comments), random_state=42)\n",
        "    balanced_data = pd.concat([toxic_sample, non_toxic_comments])\n",
        "\n",
        "# Shuffling the balanced dataset for randomness and resetting the index\n",
        "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iGeC7R6tK3tF"
      },
      "outputs": [],
      "source": [
        "# Splitting the balanced dataset into training, validation, and testing sets\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    balanced_data['comment_text'], balanced_data.iloc[:, 2:], test_size=0.25, random_state=42)\n",
        "\n",
        "test_texts, val_texts, test_labels, val_labels = train_test_split(\n",
        "    temp_texts, temp_labels, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization and Encoding using BERT for Toxic Comment Classification\n",
        "\n",
        "1. **Tokenization Function:**\n",
        "   - `tokenize_and_encode_bert` function is defined to tokenize and encode comments using the BERT tokenizer.\n",
        "   - It leverages BERT's tokenization to convert comments into numerical representations suitable for model input.\n",
        "   - BERT tokenization allows the model to understand contextual information and relationships between words.\n",
        "\n",
        "2. **BERT Configuration:**\n",
        "   - BERT tokenizer (`bert_tokenizer`) is loaded from 'bert-base-uncased' with case-insensitivity.\n",
        "   - BERT model (`bert_model`) for sequence classification with six labels is loaded.\n",
        "   - 'bert-base-uncased' is chosen for its balanced performance and efficiency in handling uncased text.\n",
        "\n",
        "3. **Data Preparation:**\n",
        "   - Training, testing, and validation datasets are tokenized and encoded using the `tokenize_and_encode_bert` function.\n",
        "   - Input IDs, attention masks, and labels are converted to PyTorch datasets (`train_dataset`, `test_dataset`, `val_dataset`).\n",
        "   - Data loaders (`train_loader`, `test_loader`, `val_loader`) are created for efficient batch processing.\n",
        "\n",
        "4. **Optimization:**\n",
        "   - AdamW optimizer is instantiated for fine-tuning BERT model parameters.\n",
        "   - AdamW is chosen for its ability to handle weight decay in a way that suits transformer-based models like BERT.\n",
        "   - The learning rate is set to 2e-5 to balance training speed and convergence.\n",
        "\n",
        "This markdown summarizes the implementation of BERT-based tokenization and encoding for toxic comment classification. The chosen tokenizer and BERT configuration enhance the model's ability to understand language nuances, while AdamW optimizer is employed for effective fine-tuning during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "shMGlu7uK3tG"
      },
      "outputs": [],
      "source": [
        "# Tokenization and Encoding using BERT for Toxic Comment Classification\n",
        "# Objective: Convert comments into numerical representations suitable for BERT model input.\n",
        "\n",
        "def tokenize_and_encode_bert(tokenizer, comments, labels, max_length=128):\n",
        "    # Lists to store tokenized input IDs and attention masks\n",
        "    input_ids, attention_masks = [], []\n",
        "    \n",
        "    # Iterate through comments for tokenization\n",
        "    for comment in comments:\n",
        "        # Encode comment using BERT tokenizer\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            comment, add_special_tokens=True, max_length=max_length,\n",
        "            pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n",
        "        \n",
        "        # Append input IDs and attention masks\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Concatenate lists to create tensors\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    \n",
        "    # Convert labels to PyTorch tensor\n",
        "    labels = torch.tensor(labels.values, dtype=torch.float32)\n",
        "\n",
        "    # Return tokenized input IDs, attention masks, and labels\n",
        "    return input_ids, attention_masks, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ocSivgP1K3tG"
      },
      "outputs": [],
      "source": [
        "# BERT Tokenizer Initialization\n",
        "# Objective: Load BERT tokenizer for tokenizing and encoding text data.\n",
        "\n",
        "# Using BERT-base-uncased model with lowercase tokens\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XEcdyyWK3tG",
        "outputId": "758dd3c3-b829-45d3-d1b5-00c4ea9db8f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# BERT Model Initialization\n",
        "# Objective: Load BERT model for sequence classification with specified configuration.\n",
        "\n",
        "# Using BERT-base-uncased model with 6 output labels for toxic comment classification\n",
        "# Moving the model to GPU if available, otherwise using CPU\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', num_labels=6).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxL9qvL5K3tH",
        "outputId": "113b7a2e-9e36-45e8-c89c-5b4e2b5fa3ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Tokenization and Encoding for BERT\n",
        "# Objective: Tokenize and encode comments using the BERT tokenizer, and prepare input tensors.\n",
        "\n",
        "# Tokenizing and encoding training set comments\n",
        "train_inputs, train_masks, train_labels = tokenize_and_encode_bert(\n",
        "    bert_tokenizer, train_texts, train_labels)\n",
        "\n",
        "# Tokenizing and encoding test set comments\n",
        "test_inputs, test_masks, test_labels = tokenize_and_encode_bert(\n",
        "    bert_tokenizer, test_texts, test_labels)\n",
        "\n",
        "# Tokenizing and encoding validation set comments\n",
        "val_inputs, val_masks, val_labels = tokenize_and_encode_bert(\n",
        "    bert_tokenizer, val_texts, val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7XNugSTHK3tH"
      },
      "outputs": [],
      "source": [
        "# Creating PyTorch DataLoader for BERT\n",
        "# Objective: Create DataLoader instances for training, testing, and validation sets.\n",
        "\n",
        "# Creating training dataset\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "# Creating test dataset\n",
        "test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "\n",
        "# Creating validation dataset\n",
        "val_dataset = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "\n",
        "# Setting batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Creating training DataLoader with random sampling\n",
        "train_loader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "\n",
        "# Creating test DataLoader with sequential sampling\n",
        "test_loader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "# Creating validation DataLoader with sequential sampling\n",
        "val_loader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "W4UCfbhRK3tI"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(bert_model.parameters(), lr=2e-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training and Evaluating BERT Model for Toxicity Classification\n",
        "\n",
        "## Objective:\n",
        "Train a BERT model to classify toxic comments into various categories using a specified DataLoader, optimizer, and device. Evaluate the model's performance on test data and make toxicity predictions for user input.\n",
        "\n",
        "## Steps:\n",
        "\n",
        "### 1. Training BERT Model:\n",
        "- **Objective:** Train the BERT model on the training data.\n",
        "- **Steps:**\n",
        "  - Utilize a custom function `train_bert_model` to handle training with specified DataLoader, optimizer, and device.\n",
        "  - Iterate through epochs, setting the model to training mode, calculating loss, and backpropagating.\n",
        "\n",
        "### 2. Evaluating BERT Model:\n",
        "- **Objective:** Evaluate the BERT model on the test data.\n",
        "- **Steps:**\n",
        "  - Utilize a custom function `evaluate_bert_model` to assess accuracy, precision, and recall.\n",
        "  - Threshold predicted probabilities and calculate evaluation metrics using scikit-learn.\n",
        "\n",
        "### 3. Predicting User Input:\n",
        "- **Objective:** Make toxicity predictions for user input.\n",
        "- **Steps:**\n",
        "  - Utilize a custom function `predict_user_input` to tokenize, encode, and predict toxicity labels for user input.\n",
        "\n",
        "## Components Used:\n",
        "\n",
        "- **BERT Model:** Utilizing a pre-trained BERT model for sequence classification with six toxicity labels.\n",
        "- **DataLoader:** Loading and iterating through the balanced training, testing, and validation datasets in batches.\n",
        "- **Optimizer:** Implementing AdamW optimizer for model training.\n",
        "- **Tokenizer:** Using the BERT tokenizer to encode comments for model input.\n",
        "- **Device:** Training and prediction on GPU if available, else on CPU.\n",
        "\n",
        "## Why Pretrained Encoder-Transformers like BERT:\n",
        "\n",
        "- **Effectiveness:** Pretrained models like BERT capture contextual information, enhancing performance on complex tasks like toxicity classification.\n",
        "- **Transfer Learning:** Leveraging knowledge from a large pretraining dataset accelerates learning on a smaller task-specific dataset.\n",
        "- **Semantic Understanding:** BERT's contextual embeddings help discern nuances and contextual meanings in text, crucial for toxicity assessment.\n",
        "- **Efficiency:** Pretrained models reduce the need for extensive training on task-specific data, saving computational resources.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJPKnN7XK3tJ",
        "outputId": "7913b705-96ad-4858-a777-51cea24a6eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 - Training Loss: 0.1982150400808857, Validation Loss: 0.15240689619319644\n",
            "Epoch 2/3 - Training Loss: 0.1365145442960845, Validation Loss: 0.14957816452961267\n",
            "Epoch 3/3 - Training Loss: 0.11254309388991254, Validation Loss: 0.15509002415214\n"
          ]
        }
      ],
      "source": [
        "# Training BERT Model\n",
        "# Objective: Train the BERT model on the training data using the specified DataLoader, optimizer, and device.\n",
        "\n",
        "def train_bert_model(model, train_loader, optimizer, device, num_epochs=3):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss, total_val_loss = 0, 0\n",
        "\n",
        "        # Training\n",
        "        for batch in train_loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "                outputs = model(**inputs)\n",
        "                loss = outputs.loss\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        # Print epoch-wise training and validation losses\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} - Training Loss: {total_loss/len(train_loader)}, Validation Loss: {total_val_loss/len(val_loader)}\")\n",
        "\n",
        "\n",
        "# Training BERT model using defined function\n",
        "train_bert_model(bert_model, train_loader, optimizer, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LjgnIskzK3tK"
      },
      "outputs": [],
      "source": [
        "# train_bert_model(bert_model, train_loader, optimizer, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcX9lhW-K3tK",
        "outputId": "6805b7b1-7288-4376-ce55-0758fc4bd63f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7133\n",
            "Precision: 0.8083\n",
            "Recall: 0.8590\n"
          ]
        }
      ],
      "source": [
        "# Evaluating BERT Model\n",
        "# Objective: Evaluate the BERT model on the test data using the specified DataLoader and device.\n",
        "\n",
        "def evaluate_bert_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    true_labels, predicted_probs = [], []\n",
        "\n",
        "    # Testing\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
        "            outputs = model(**inputs)\n",
        "            logits = torch.sigmoid(outputs.logits)\n",
        "            predicted_probs.extend(logits.cpu().numpy())\n",
        "            true_labels.extend(batch[2].cpu().numpy())\n",
        "\n",
        "    # Thresholding predicted probabilities\n",
        "    predicted_labels = (np.array(predicted_probs) > 0.5).astype(int)\n",
        "\n",
        "    # Calculating evaluation metrics\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average='micro')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='micro')\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "\n",
        "\n",
        "# Evaluating BERT model using defined function\n",
        "evaluate_bert_model(bert_model, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4C29rVLTOuW",
        "outputId": "51027e3b-476d-4e69-80a7-c0a678c40817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Saved_model/tokenizer_config.json',\n",
              " 'Saved_model/special_tokens_map.json',\n",
              " 'Saved_model/vocab.txt',\n",
              " 'Saved_model/added_tokens.json')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the tokenizer and model in the same directory\n",
        "output_dir = \"Saved_model\"\n",
        "# Save model's state dictionary and configuration\n",
        "bert_model.save_pretrained(output_dir)\n",
        "# Save tokenizer's configuration and vocabulary\n",
        "bert_tokenizer.save_pretrained(output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sEjxyduuTRdJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"Saved_model\"\n",
        "Bert_Tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "Bert_Model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9u5ISBpTK00",
        "outputId": "e9a6404a-1133-4e3e-f6c5-ef3d93349e51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'toxic': 0,\n",
              " 'severe_toxic': 0,\n",
              " 'obscene': 0,\n",
              " 'threat': 0,\n",
              " 'insult': 0,\n",
              " 'identity_hate': 0}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predicting User Input\n",
        "# Objective: Make toxicity predictions for user input using the BERT model, tokenizer, and specified device.\n",
        "\n",
        "def predict_user_input(input_text, model=Bert_Model, tokenizer=Bert_Tokenizer, device=device):\n",
        "    # Tokenize and encode user input\n",
        "    user_input = [input_text]\n",
        "    user_encodings = tokenizer(\n",
        "        user_input, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "    user_dataset = TensorDataset(\n",
        "        user_encodings['input_ids'], user_encodings['attention_mask'])\n",
        "    user_loader = DataLoader(user_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Model prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in user_loader:\n",
        "            input_ids, attention_mask = [t.to(device) for t in batch]\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.sigmoid(logits)\n",
        "\n",
        "    # Thresholding predicted probabilities\n",
        "    predicted_labels = (predictions.cpu().numpy() > 0.5).astype(int)\n",
        "\n",
        "    # Creating a dictionary with predicted labels\n",
        "    labels_list = ['toxic', 'severe_toxic', 'obscene',\n",
        "                   'threat', 'insult', 'identity_hate']\n",
        "    result = dict(zip(labels_list, predicted_labels[0]))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Example: Predicting toxicity for a user input\n",
        "text = 'Hi, how are you?'\n",
        "predict_user_input(input_text=text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knYF4x8gTLj1",
        "outputId": "7b0b6e12-3cb2-4c83-9696-091ff54f0fb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'toxic': 1,\n",
              " 'severe_toxic': 0,\n",
              " 'obscene': 1,\n",
              " 'threat': 0,\n",
              " 'insult': 1,\n",
              " 'identity_hate': 0}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'Are you stupid?'\n",
        "predict_user_input(input_text=text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTHjaHJeT_jJ",
        "outputId": "e3990a09-46fd-4a58-b9b8-8b7eda5f525a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'toxic': 0,\n",
              " 'severe_toxic': 0,\n",
              " 'obscene': 0,\n",
              " 'threat': 0,\n",
              " 'insult': 0,\n",
              " 'identity_hate': 0}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'Machine learning is hard'\n",
        "predict_user_input(input_text=text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNMWSy1lUFYL",
        "outputId": "40adccba-add4-4037-e3bf-1211b225cdb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'toxic': 1,\n",
              " 'severe_toxic': 0,\n",
              " 'obscene': 0,\n",
              " 'threat': 0,\n",
              " 'insult': 1,\n",
              " 'identity_hate': 0}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'You are Dumb!'\n",
        "predict_user_input(input_text=text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "T3tCJfM-WztG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "def print_classification_metrics(true_labels, predicted_labels):\n",
        "    class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(f\"Metrics for class: {class_name}\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(true_labels[:, i], predicted_labels[:, i]))\n",
        "        print(\"Precision: {:.2f}\".format(precision_score(true_labels[:, i], predicted_labels[:, i])))\n",
        "        print(\"Recall: {:.2f}\".format(recall_score(true_labels[:, i], predicted_labels[:, i])))\n",
        "        print(\"F1-Score: {:.2f}\".format(f1_score(true_labels[:, i], predicted_labels[:, i])))\n",
        "        print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAyMJlJkVHiQ",
        "outputId": "d7313c1c-d847-40b3-ceb6-a851b550b898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for class: toxic\n",
            "Confusion Matrix:\n",
            "[[1940  208]\n",
            " [ 109 1799]]\n",
            "Precision: 0.90\n",
            "Recall: 0.94\n",
            "F1-Score: 0.92\n",
            "------------------------------\n",
            "Metrics for class: severe_toxic\n",
            "Confusion Matrix:\n",
            "[[3757   95]\n",
            " [ 105   99]]\n",
            "Precision: 0.51\n",
            "Recall: 0.49\n",
            "F1-Score: 0.50\n",
            "------------------------------\n",
            "Metrics for class: obscene\n",
            "Confusion Matrix:\n",
            "[[2802  222]\n",
            " [ 123  909]]\n",
            "Precision: 0.80\n",
            "Recall: 0.88\n",
            "F1-Score: 0.84\n",
            "------------------------------\n",
            "Metrics for class: threat\n",
            "Confusion Matrix:\n",
            "[[3961   32]\n",
            " [  16   47]]\n",
            "Precision: 0.59\n",
            "Recall: 0.75\n",
            "F1-Score: 0.66\n",
            "------------------------------\n",
            "Metrics for class: insult\n",
            "Confusion Matrix:\n",
            "[[2832  233]\n",
            " [ 218  773]]\n",
            "Precision: 0.77\n",
            "Recall: 0.78\n",
            "F1-Score: 0.77\n",
            "------------------------------\n",
            "Metrics for class: identity_hate\n",
            "Confusion Matrix:\n",
            "[[3792   99]\n",
            " [  44  121]]\n",
            "Precision: 0.55\n",
            "Recall: 0.73\n",
            "F1-Score: 0.63\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "def evaluate_bert_model_for_classification(model, test_loader, device):\n",
        "    model.eval()\n",
        "    true_labels, predicted_probs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n",
        "            outputs = model(**inputs)\n",
        "            logits = torch.sigmoid(outputs.logits)\n",
        "            predicted_probs.extend(logits.cpu().numpy())\n",
        "            true_labels.extend(batch[2].cpu().numpy())\n",
        "\n",
        "    predicted_labels = (np.array(predicted_probs) > 0.5).astype(int)\n",
        "    return np.array(true_labels), predicted_labels\n",
        "\n",
        "# Call the modified evaluation function and get true and predicted labels\n",
        "true_labels, predicted_labels = evaluate_bert_model_for_classification(bert_model, test_loader, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "# Now call the print_classification_metrics function with the true and predicted labels\n",
        "print_classification_metrics(true_labels, predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmCBuQB9WS7_",
        "outputId": "c17aaad4-8a7e-4eb6-abc5-b525eaea2739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for class: toxic\n",
            "Class 0: Precision: 0.95, Recall: 0.90, F1-Score: 0.92\n",
            "Class 1: Precision: 0.90, Recall: 0.94, F1-Score: 0.92\n",
            "Confusion Matrix:\n",
            "[[1940  208]\n",
            " [ 109 1799]]\n",
            "------------------------------\n",
            "Metrics for class: severe_toxic\n",
            "Class 0: Precision: 0.97, Recall: 0.98, F1-Score: 0.97\n",
            "Class 1: Precision: 0.51, Recall: 0.49, F1-Score: 0.50\n",
            "Confusion Matrix:\n",
            "[[3757   95]\n",
            " [ 105   99]]\n",
            "------------------------------\n",
            "Metrics for class: obscene\n",
            "Class 0: Precision: 0.96, Recall: 0.93, F1-Score: 0.94\n",
            "Class 1: Precision: 0.80, Recall: 0.88, F1-Score: 0.84\n",
            "Confusion Matrix:\n",
            "[[2802  222]\n",
            " [ 123  909]]\n",
            "------------------------------\n",
            "Metrics for class: threat\n",
            "Class 0: Precision: 1.00, Recall: 0.99, F1-Score: 0.99\n",
            "Class 1: Precision: 0.59, Recall: 0.75, F1-Score: 0.66\n",
            "Confusion Matrix:\n",
            "[[3961   32]\n",
            " [  16   47]]\n",
            "------------------------------\n",
            "Metrics for class: insult\n",
            "Class 0: Precision: 0.93, Recall: 0.92, F1-Score: 0.93\n",
            "Class 1: Precision: 0.77, Recall: 0.78, F1-Score: 0.77\n",
            "Confusion Matrix:\n",
            "[[2832  233]\n",
            " [ 218  773]]\n",
            "------------------------------\n",
            "Metrics for class: identity_hate\n",
            "Class 0: Precision: 0.99, Recall: 0.97, F1-Score: 0.98\n",
            "Class 1: Precision: 0.55, Recall: 0.73, F1-Score: 0.63\n",
            "Confusion Matrix:\n",
            "[[3792   99]\n",
            " [  44  121]]\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score\n",
        "\n",
        "def print_classification_metrics_invidiual_classes(true_labels, predicted_labels):\n",
        "    class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(f\"Metrics for class: {class_name}\")\n",
        "\n",
        "        # Calculating metrics for class 0\n",
        "        precision_0 = precision_score(true_labels[:, i], predicted_labels[:, i], pos_label=0)\n",
        "        recall_0 = recall_score(true_labels[:, i], predicted_labels[:, i], pos_label=0)\n",
        "        f1_0 = f1_score(true_labels[:, i], predicted_labels[:, i], pos_label=0)\n",
        "\n",
        "        # Calculating metrics for class 1\n",
        "        precision_1 = precision_score(true_labels[:, i], predicted_labels[:, i], pos_label=1)\n",
        "        recall_1 = recall_score(true_labels[:, i], predicted_labels[:, i], pos_label=1)\n",
        "        f1_1 = f1_score(true_labels[:, i], predicted_labels[:, i], pos_label=1)\n",
        "\n",
        "        # Printing metrics\n",
        "        print(f\"Class 0: Precision: {precision_0:.2f}, Recall: {recall_0:.2f}, F1-Score: {f1_0:.2f}\")\n",
        "        print(f\"Class 1: Precision: {precision_1:.2f}, Recall: {recall_1:.2f}, F1-Score: {f1_1:.2f}\")\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(true_labels[:, i], predicted_labels[:, i])\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(cm)\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "# Call this function with the true and predicted labels\n",
        "print_classification_metrics_invidiual_classes(true_labels, predicted_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Findings\n",
        "\n",
        "### Toxic:\n",
        "The model achieves robust performance in distinguishing toxic and non-toxic comments, yielding an overall accuracy of 92%. Precision for non-toxic comments is high (0.95), with a balanced recall of 0.90. For toxic comments, precision remains strong at 0.90, with an improved recall of 0.94, resulting in an impressive F1-Score of 0.92.\n",
        "\n",
        "### Severe Toxic:\n",
        "The model exhibits excellent accuracy, reaching 97%, in classifying severe toxic and non-severe toxic comments. Precision for non-severe toxic comments is exceptionally high (0.97), coupled with a recall of 0.98. However, for severe toxic comments, there is a trade-off with precision dropping to 0.51, and recall at 0.49, resulting in a moderate F1-Score of 0.50.\n",
        "\n",
        "### Obscene:\n",
        "The model performs admirably in distinguishing obscene and non-obscene comments, achieving an accuracy of 94%. Precision for non-obscene comments is notably high (0.96), with a balanced recall of 0.93. For obscene comments, precision is commendable at 0.80, and recall improves to 0.88, resulting in a robust F1-Score of 0.84.\n",
        "\n",
        "### Threat:\n",
        "With an outstanding accuracy of 99%, the model excels in identifying non-threatening and threatening comments. Precision for non-threatening comments is perfect (1.00), accompanied by an impressive recall of 0.99. However, for threatening comments, precision is moderate (0.59), and recall is 0.75, yielding a balanced F1-Score of 0.66.\n",
        "\n",
        "In summary, the model demonstrates consistent and effective performance across various classes, with specific precision-recall trade-offs in severe toxic and threatening comments. Achieving a balance between precision and recall remains crucial for different application scenarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "It is clear that Pre Encoded transfomer using BERT performed the best out of the lot, producing high accuracy and relatively satisfying F1, precision, and recall scores, compared to other models. This is unsurpsing, as Transformers are the state of the art in Natural language procesing. Indeed it performed brilliantly well in custom trained sentences we formed and put into.\n",
        "\n",
        "While improvements could follow better data pre processing of enabling URLS etc, and maybe perhaps better mutli class data sampling, the results of this model on its own suggest a good trained model. BERT performs the best out of all the three models, in almost all cases. Hence, Model 3> Model 2> Model 1 follows, BERT performing the best, and OUR state of art model.\n",
        "\n",
        "This is all from our side, Thank you for reading :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model was heavily complex wo we had to do multiple readings, one of the main sources we were inspired by  was:\n",
        "https://www.geeksforgeeks.org/toxic-comment-classification-using-bert/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
